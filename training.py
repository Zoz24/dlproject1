# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oA0KYjHuzR7ae_ztUEMq8aZWfoVVpU_h

# Training
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive') 
# %cd "/content/drive/MyDrive/Colab Notebooks/P_1.2"

import numpy as np
import os
import pathlib
import tensorflow as tf
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import Sequential
from tensorflow.keras import layers, models
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, MaxPooling2D, Activation

# Default parameters, modify and find what's best for your model
batch_size = 128
img_size = 256
learning_rate = 0.0005
num_epochs = 30
dropout = 0.2
patience = 10

def load_dataset(ds, mode):

  def process_path(file_path):
    parts = tf.strings.split(file_path, os.path.sep)
    one_hot = parts[-2] == class_names
    label = tf.cast(one_hot, dtype='int64')  # Create labels
    img = tf.io.read_file(file_path)  # Read file
    img = tf.io.decode_jpeg(img, channels=3)  # Convert image to tensor
    img = tf.image.convert_image_dtype(img, tf.float32) # Normalize image in the range of 0 and 1
    img = tf.image.resize(img, [img_size, img_size])    # Resize the image
    return img, label

  def transformation(image, label):
    # Apply transformations to images 
    # the type of transformation (augmentations) used is different at train and evaluation time.
    if mode == 'train':  
      img = tf.image.central_crop(image, 0.7)
      img = tf.image.resize_with_pad(img, img_size, img_size)
      img = tf.clip_by_value(img, 0.0,1.0)    # To make sure images are in the range of 0 and 1 after transformations
      return img, label
    else:
      img = tf.clip_by_value(image, 0.0,1.0) 
      return img, label

  def configuration(dataset):
    # Configurations to optimize the performance
    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.cache()
    dataset = dataset.map(transformation, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.batch(batch_size=batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    return dataset
  
  # Load and generate dataset
  data_dir = pathlib.Path("data/" + ds) # Specify the path to data folder
  image_count = len(list(data_dir.glob('*/*.jpg')))
  files_list = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)
  files_list = files_list.shuffle(image_count, reshuffle_each_iteration=False)
  class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
  print("Loading {} dataset!".format(ds))
  print("Number of classes: {}.".format(len(class_names)))
  print("Data size: {}.".format(image_count))
  print(" ---------- --------- ---------- \n")
  return configuration(files_list)

# Prepare train and valid dataset
train_ds = load_dataset(ds = 'train', mode='train')
valid_ds = load_dataset(ds = 'valid', mode=None)

# Best Model found
num_classes = 11
model = Sequential()
resnet_model = tf.keras.applications.resnet50.ResNet50(input_shape = (img_size,img_size,3), weights="imagenet", include_top = False, pooling = 'avg')
model.add(resnet_model)
model.add(Dense(num_classes, activation = 'softmax'))

model.summary()
model.compile(
    optimizer = "sgd",
    loss = 'categorical_crossentropy',
    metrics=['accuracy'])

'''Alternate model with pretrained model vgg16'''
# vgg16_model = tf.keras.applications.vgg16.VGG16(include_top = False, weights = 'imagenet', pooling = 'maxpooling', input_shape = (img_size, img_size, 3))
 
# vgg16_model_touse = tf.keras.models.Model(inputs = vgg16_model.input, outputs= vgg16_model.get_layer('block3_pool').output)
 
 
# model = Sequential()
# model.add(vgg16_model_touse)
 
# model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',
#                  activation='relu', input_shape=(img_size, img_size, 3)))
 
# model.add(Conv2D(32, (3,3), activation='relu'))
# model.add(MaxPooling2D((2,2)))  
# model.add(Dropout(0.2))
 
# model.add(Conv2D(64, (3,3), padding='same', activation='relu'))
# model.add(Conv2D(64, (3,3), activation='relu'))
# model.add(MaxPooling2D((2,2)))
# model.add(Dropout(0.2))
 
# model.add(Conv2D(128, (3,3), padding='same', activation='relu'))
# model.add(Conv2D(128, (3,3), activation='relu'))
# model.add(Activation('relu'))
# model.add(MaxPooling2D((2,2)))
# model.add(Dropout(0.2))
 
 
# model.add(Flatten())
# model.add(Dense(1024, activation='relu'))
# model.add(Dropout(0.2))
# model.add(Dense(11, activation='softmax'))
 
# model.summary()
# model.layers[0].trainable = False

# Make sure to use h5 format to save model
callbacks = [EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='min'), 
            ModelCheckpoint(filepath='model.h5', verbose=1, monitor='val_loss', save_best_only=True, save_weights_only=False, mode='min')]

model.fit(
  train_ds,
  epochs=num_epochs,
  validation_data=valid_ds,
  callbacks=callbacks
)